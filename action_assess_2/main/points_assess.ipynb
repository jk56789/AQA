{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 29, 32]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13]\n",
      "[0, 1, 2, 4, 5, 6]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "def read_keypoints_from_csv(csv_file):\n",
    "    keypoints = []\n",
    "    with open(csv_file, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader)\n",
    "        for row in reader:\n",
    "            frame_keypoints = []\n",
    "            for i in range(33):\n",
    "                x = float(row[1 + i*4])\n",
    "                y = float(row[2 + i*4])\n",
    "                z = float(row[3 + i*4])\n",
    "                visibility = float(row[4 + i*4])\n",
    "                frame_keypoints.append(landmark_pb2.NormalizedLandmark(x=x, y=y, z=z, visibility=visibility))\n",
    "            keypoints.append(frame_keypoints)\n",
    "    return keypoints\n",
    "\n",
    "def extract_frame(video_path, frame_index):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    if not ret:\n",
    "        raise ValueError(f\"Could not read frame {frame_index} from {video_path}\")\n",
    "    return frame\n",
    "\n",
    "def draw_landmarks(image, landmarks, color):\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose_landmarks = landmark_pb2.NormalizedLandmarkList(landmark=landmarks)\n",
    "    mp_drawing.draw_landmarks(image, pose_landmarks, mp_pose.POSE_CONNECTIONS, \n",
    "                                mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=2),\n",
    "                                mp_drawing.DrawingSpec(color=color, thickness=2, circle_radius=2))\n",
    "    return image\n",
    "\n",
    "def compare_and_visualize(video_file1, video_file2, csv_file1, csv_file2, frame1_index, frame2_index, output_image, distance_threshold=0.04):\n",
    "    keypoints1 = read_keypoints_from_csv(csv_file1)\n",
    "    keypoints2 = read_keypoints_from_csv(csv_file2)\n",
    "\n",
    "    frame1_7 = extract_frame(video_file1, frame1_index)\n",
    "    frame2_9 = extract_frame(video_file2, frame2_index)\n",
    "\n",
    "    highlight_indices = []\n",
    "    for i in range(33):\n",
    "        observation1 = np.array([keypoints1[frame1_index][i].x, keypoints1[frame1_index][i].y])\n",
    "        observation2 = np.array([keypoints2[frame2_index][i].x, keypoints2[frame2_index][i].y])\n",
    "        observation_distance = np.linalg.norm(observation1 - observation2)\n",
    "        if observation_distance > distance_threshold:\n",
    "            highlight_indices.append(i)\n",
    "        '''print(f'observation_distance_{i}:', round(observation_distance, 3))\n",
    "        print('#' * 100)'''\n",
    "    print(highlight_indices)\n",
    "\n",
    "    score = max(0, 100 - observation_distance)\n",
    "\n",
    "    image1 = draw_landmarks(frame1_7, keypoints1[frame1_index], (0, 255, 255))\n",
    "    image2 = draw_landmarks(frame2_9, keypoints2[frame2_index], (0, 255, 0))\n",
    "    \n",
    "    for idx in highlight_indices:\n",
    "        landmark = keypoints2[frame2_index][idx]\n",
    "        cv2.circle(image2, (int(landmark.x * image2.shape[1]), int(landmark.y * image2.shape[0])), 20, (0, 0, 255), -1)\n",
    "\n",
    "    combined_image = np.concatenate((image1, image2), axis=1)\n",
    "\n",
    "    cv2.putText(combined_image, f'Score: {score}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(combined_image, f'threshold: {round(distance_threshold,3)}', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(combined_image, 'Points', (1700, 200), cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 0, 0), 10, cv2.LINE_AA)\n",
    "    cv2.imwrite(output_image, image2)\n",
    "\n",
    "# 사용 예시\n",
    "video_file1 = 'C:/Users/jk/action_assess_2/data/video/Z76/313-2-1-15-Z76_D.avi'\n",
    "video_file2 = 'C:/Users/jk/action_assess_2/data/video/Z106/313-2-1-15-Z106_D.avi'\n",
    "csv_file1 = 'C:/Users/jk/action_assess_2/data/csv/Z76/313-2-1-15-Z76_D.csv'\n",
    "csv_file2 = 'C:/Users/jk/action_assess_2/data/csv/Z106/313-2-1-15-Z106_D.csv'\n",
    "output_image = 'C:/Users/jk/action_assess_2/post_data/points/output_image.png'\n",
    "\n",
    "for threshold in np.arange(0.01, 0.10, 0.015):\n",
    "    output_image = f'C:/Users/jk/action_assess_2/post_data/points/output_image_{round(threshold,3)}.png'\n",
    "    compare_and_visualize(video_file1, video_file2, csv_file1, csv_file2, 4, 4, output_image, distance_threshold=threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poserac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
